1) Glance of Time Complexity:- 

The time complexity doesn't indicate the exact execution time of an algorithm instead it gives an idea of the variation of time with a corresponding variation of input size.

2) Introduction to Amortized time complexity:- 

Amortized time complexity is the "Expected Time Complexity" used to express time complexity when an algorithm has expensive worst-case time complexity once in a while compared to the time complexity that occurs most of the time.

Amortized complexity is used when algorithms have expensive operations that occur rarely.


3) Understanding amortization using Dynamic Array:- 

Dynamic Array is the best example to understand Amortized Time complexity.

A dynamic array is a linear data structure that is growable and shrinkable in size upon necessity.

vector in C++ and ArrayList in Java and List in Python use the concept of Dynamic array in their implementation.

There arise two cases for insertion in the dynamic array:-

1. When there exists free space in the array.

Time complexity here is O(1).


2. When there is no space, a new array is to be created of size double the original array, the elements in the original array are to be copied, and the new element is inserted.


Time complexity here is:- 
Creation of a new array of double the original size
+
Copying the elements of the original array


                    Insertion of the new element

⇒  O(2N) + O(N) + O(1) = O(3N+1) 
                        where N is the size of the original array.

4) Analysing the worst-case time complexity:- 

Suppose that we are doing an insertion operation on the array for N times where N is the size of the array. In the worst case, each operation takes O(3N) time complexity.

Time complexity for overall operation is N×O(3N)=O(3N^2)

Ignoring constant,

The worst-case time complexity for N insertions is O(N^2).


5) Analysing Amortized Complexity:- 

The amortized analysis averages the running times of operations in a sequence.

Assume the initial size of the array is 1
Insert 1 






 Time: 1


Now, there is no space for insertion hence take an array of size double that of the original array i.e., 2







Copy the elements of the original array i.e., 1

Insert 2 



Time: 2+1+1=4 

Now, there is no space for insertion hence take an array of size double that of the original array i.e., 4 





Copy the elements of the original array i.e., 1,2






Insert 3

Time:4+2+1=7 

Insert 4 





Time: 1

and so on...

Assume there would be m appends.

Hence the cost of m appends would be m since we are appending m elements(the append operation would cost O(1)) plus the cost of doubling when the array needs to grow.

Let's calculate the cost of doubling the array:- 

The first doubling costs 1, the second doubling costs 2, the third doubling costs 4...and so on.

⇒ 1+2+4+6+8+.......+m/2+m

It's easier to solve the above equation if we reverse it.

⇒ m+m/2+.......+8+6+4+2+1










The highlighted box equals to m summing the total to 2m.

Hence keeping everything together appends cost (m) and doubling costs (2m).
The total sum would be 3m i.e., O(m).

Therefore m appends costs O(m). So each append costs O(1).

This is amortized complexity for dynamic arrays.


